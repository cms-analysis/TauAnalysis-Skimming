[CRAB]
#
#   This section contains the default values for general parameters.
#   They can be set also as a command-line option, i.e.
#
#   key1 = value1
#   [SECTION]
#   key2 = value2
#
#   in this section corresponds to
#
#   crab.py -key1=value1 -key2=SECTION.value2
#
#   in the command line.
#
jobtype = cmssw
#scheduler = edg 
scheduler = glite
#scheduler = glitecoll

[CMSSW]

### The data you want to access (to be found on DBS) 
### /primarydataset/datatier/processeddataset
### can be "None" for no input

#datasetpath=/RelValQCD_Pt_120_170/CMSSW_2_1_0_pre6-RelVal-1214239099-STARTUP_V1-2nd/GEN-SIM-DIGI-RAW-HLTDEBUG-RECO
#datasetpath=/RelValQCD_Pt_80_120/CMSSW_2_1_0_pre6-RelVal-1213921089-STARTUP_V1-2nd/GEN-SIM-DIGI-RAW-HLTDEBUG-RECO


#datasetpath=/RelValQCD_Pt_15_20/CMSSW_2_1_0_pre6-RelVal-1214239099-STARTUP_V1-2nd/GEN-SIM-DIGI-RAW-HLTDEBUG-RECO

#datasetpath=/RelValQCD_Pt_20_30/CMSSW_2_1_0_pre6-RelVal-1214239099-STARTUP_V1-2nd/GEN-SIM-DIGI-RAW-HLTDEBUG-RECO

#datasetpath=/RelValQCD_Pt_50_80/CMSSW_2_1_0_pre6-RelVal-1214239099-STARTUP_V1-2nd/GEN-SIM-DIGI-RAW-HLTDEBUG-RECO

#datasetpath=/RelValQCD_Pt_80_120/CMSSW_2_1_0_pre6-RelVal-1213921089-STARTUP_V1-2nd/GEN-SIM-DIGI-RAW-HLTDEBUG-RECO 	
	
#datasetpath=/RelValQCD_Pt_120_170/CMSSW_2_1_0_pre6-RelVal-1214239099-STARTUP_V1-2nd/GEN-SIM-DIGI-RAW-HLTDEBUG-RECO 	
	
#datasetpath=/RelValZEE/CMSSW_2_1_0_pre6-RelVal-1213921089-STARTUP_V1-2nd/GEN-SIM-DIGI-RAW-HLTDEBUG-RECO

#datasetpath=/RelValZTT/CMSSW_2_1_0_pre6-RelVal-1213921089-STARTUP_V1-2nd/GEN-SIM-DIGI-RAW-HLTDEBUG-RECO

#datasetpath = /QCDpt30/Winter09_IDEAL_V11_FastSim_v1/GEN-SIM-DIGI-RECO
#datasetpath = /Ztautau/Summer08_IDEAL_V11_redigi_v1/GEN-SIM-RECO
datasetpath=skimdataset

### DBS/DLS options
# use_dbs_1 = 0
# dbs_url = http://cmsdoc.cern.ch/cms/test/aprom/DBS/CGIServer/prodquery
# dbs_version = v00_00_06
# dbs_instance = MCGlobal/Writer
# dls_type = mysql
# dls_endpoint = lfc-cms-test.cern.ch/grid/cms/DLS/LFC

### The ParameterSet you want to use
#pset=/home/cmsprod/NewAnalysis/official/CMSSW_1_3_1_HLT6/src/HLTrigger/Muon/test/HLTTwoMuonTwoElectron.cfg
#pset=/afs/cern.ch/user/l/lusito/scratch0/FastSim/CMSSW_1_6_9/src/UserAnalysisCode/ZTauTauAnalysis/test/analisiNicFull.cfg

#pset=/afs/cern.ch/user/l/lusito/CMSSW_2_1_0_pre6/src/RunHLTDQM.cfg

pset= /afs/cern.ch/user/l/lusito/scratch0/CMSSW_2_2_3/src/TauAnalysis/Skimming/test/skimMuTau_cfg.py

### Total number of events to be accessed: -1 means all ("-1" is not usable if no input)
#total_number_of_events=9000 
#total_number_of_events=10

### Number of events to be processed per job
events_per_job = 1000

### Number of jobs
number_of_jobs = 1

### The output files produced by your application (comma separated list)
output_file = muTauSkim.root

[USER]
################################
#### additional input file #####
################################

## files to be put in InputSandBox, full path or in the current directory
## (wildcard * are allowed): comma separated list
#additional_input_files = /home_local/fanzago/fede.txt, /home_local/fanzago/fede.prova


#################################
######### CRAB  DIR  ############
#################################

## Name of UI directory where CRAB will create job to submit (with full path).
## If commented, the default directory will be "crab_0_data_time"
# ui_working_dir = /home/cmsprod/NewAnalysis/CRAB_1_5_2/python/DY2mu_110
# ui_working_dir = /home/cmsprod/NewAnalysis/CRAB_1_5_2/python/QCD_Pt_170_230

ui_working_dir= /afs/cern.ch/user/l/lusito/scratch0/CMSSW_2_2_3/src/TauAnalysis/Skimming/test/skimdir

#################################
#### JOB OUTPUT MANAGEMENT #####
#################################

### RETRIEVE JOB OUTPUT INTO UI ###
## to have back the job executable output into UI (return_data= 1)
#return_data = 1

### If return_data = 1 ###
## UI directory where to store the CMS executable output
## FULL path is mandatory. If none <ui_working_dir>/res will be used.
#outputdir=/home/fanzago/CRAB/Crab/python/out_orca

### If return_data = 1 ###
## UI directory where to store the stderr, stdout and .BrokerInfo of submitted jobs
## FULL path is mandatory. If none <ui_working_dir>/res will be used.
#logdir=/home/fanzago/CRAB/UserTools/src/grid_job_log

### COPY JOB OUTPUT INTO A SE ###
## if you want to copy the CMS executable output into a SE (i:e castor)
### WARNING: if the copy fails and return_data = 0, the output is lost
copy_data = 1

### if copy_data = 1 ###
## name of the SE where to copy the CMS executable output.
#storage_element = pccms2.cmsfarm1.ba.infn.it

#srm_version = 1 //non si usa +

#storage_element =srm.cern.ch  
storage_element = srm-cms.cern.ch

## and the SE directory (or the mountpoint) that has to be writable from all
#storage_path = /pnfs/cmsfarm1.ba.infn.it/data/cms/letizia/Nota/Skimmed_rootfile

#storage_path = /srm/managerv2?SFN=/castor/cern.ch/user/l/lusito/DQMFamos/qcd3050

storage_path = /srm/managerv2?SFN=/castor/cern.ch
user_remote_dir = /user/l/lusito/SkimJanuary09/test/skimdir


### REGISTER JOB OUTPUT IN THE LFC CATALOG ###
## if you want also to register the CMS executable output into the LFC catalog
## WARNING: to use with copy_data = 1
#register_data = 1

### if register_data = 1
## If you register the CMS output file into the LFC catalog, this is the first part of LFN
### example LFN="lfn_dir"/"output_file"
#lfn_dir = MyDirLFN 

#################################
####### JOB MONITORING  ### #####
#################################


### Use central BOSS DB instead of one for each task: the DB must be already been setup!
use_central_bossDB = 0

### Use Boss RealTime monitoring
use_boss_rt = 1 


### To use a different set of BOSS config files specify the location here
boss_clads=

[EDG]
################################
###### EDG specific stuff ######
################################

# LCG middleware version installed on testbed
lcg_version = 2

## to change the CMS-broker RB. The ones available for CMS are "CERN" and "CNAF": the configuration
## files needed to change the broker will be automatically downloaded from CRAB web page. If the
## files are already present on the working directory they will be used. 
rb = CERN

## CMS myproxy server, to proxy delegation
proxy_server = myproxy.cern.ch 

## Role in VOMS
#role = superman

## Group in VOMS
#group = superheros

## If you don't want CRAB to check your proxy
#dont_check_proxy = 1

## to add other requirements to jdl file, as example the Operating System
#requirements = (other.GlueHostOperatingSystemName == "RedHat")

## to add other parameters to jdl file: comma separated list, each item _must_
## be complete, including the closing ";"
#additional_jdl_parameters = AllowZippedISB = false;

## cpu time and wall_clock_time(=real time) in minutes. Written into the jdl file
#max_cpu_time = 60
#max_wall_clock_time = 60

## SE Black List: all the storage elements (SE) containing the following strings (comma
## separated list) will not be considered for submission.
## for discovery, please use http://cmslcgco01.cern.ch:8001/
#se_black_list = edu

## SE White List: only the storage elements (SE) containing the following strings (comma
## separated list) will be considered for submission.
## for discovery, please use http://cmslcgco01.cern.ch:8001/
#se_white_list = infn

## CE Black List: all the CE whose name contains the following strings (comma
## separated list) will not be considered for submission.
## Use the dns domain (eg fnal, cern, ifae, fzk, cnaf, lnl,....)
# ce_black_list = fnal

## CE White List: only the CE whose name contains the following strings (comma
## separated list) will be considered for submission.
## Use the dns domain (eg fnal, cern, ifae, fzk, cnaf, lnl,....)
#ce_white_list = mit

## fields written into jdl
virtual_organization = cms

## number or retry count
retry_count = 2

## LFC catalog parameters
lcg_catalog_type = lfc
lfc_host = lfc-cms-test.cern.ch
lfc_home = /grid/cms

[CONDORG]

# Set this to condor to override the batchsystem defined in gridcat.
#batchsystem = condor

# Specify addition condor_g requirments
# use this requirment to run on a cms dedicated hardare
# globus_rsl = (condor_submit=(requirements 'ClusterName == \"CMS\" && (Arch == \"INTEL\" || Arch == \"X86_64\")'))
# use this requirement to run on the new hardware
#globus_rsl = (condor_submit=(requirements 'regexp(\"cms-*\",Machine)'))

